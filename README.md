# WordPress Content Generator

An autonomous, agent-based system that plans, writes, edits, illustrates and publishes long-form, SEO-optimised articles directly to WordPress.

> **Status:** Sprint 2 in progress â€“ `site_scaffold_agent` ready and orchestrator autoâ€‘run loop implemented.

---

## ðŸ“š Table of Contents
1. What it does  
2. Architecture overview  
3. Repository layout  
4. Quick start (local development **without Docker**)  
5. Environment variables  
6. Database schema & seed data  
7. Running agents manually  
8. Orchestrator usage  
9. Front-end scaffold  
10. Continuous integration  
11. Contributing  

---

## 1  What it does
The system automates the entire content pipeline:

* Generates keyword clusters, research citations, hooks, drafts, headlines, images â€¦
* Stores intermediate data in Supabase (PostgreSQL + Storage).
* Uses Pocketflow to route LLM calls (OpenAI to start, others later).
* Publishes finished articles to WordPress via REST API.
* Designed for scale: each step is a **stateless micro-agent** supervised by a lightweight orchestrator.

---

## 2  Architecture overview

| Layer          | Tech / Tooling |
| -------------- | -------------- |
| LLM Router     | **Pocketflow** â€“ multi-provider routing & eval |
| Agents         | Python scripts (OpenAI GPT-4/3.5) |
| Orchestrator   | `orchestrator.py` â€“ polls Supabase task table & executes agents |
| Data Store     | **Supabase** (PostgreSQL, Storage) |
| Front-end      | **Next.js** (deployed on Vercel) â€“ monitoring dashboard |
| CMS            | WordPress REST API |
| CI             | GitHub Actions â€“ lint, tests, coverage |

Agents talk **only** through the database, never directly to each other.

---

## 3  Repository layout
```
.
â”œâ”€â”€ agents/                  # All micro-agents
â”‚   â”œâ”€â”€ shared/              # common schemas & utils
â”‚   â””â”€â”€ seo-agent/           # first working stub
â”‚   â””â”€â”€ enhanced_seo_agent.py # AI-powered keyword & content ideation
â”‚   â””â”€â”€ research_agent.py     # gathers citations & facts
â”‚   â””â”€â”€ draft_writer_agent.py # turns research + keywords into full drafts
â”‚   â””â”€â”€ site_scaffold_agent/  # scaffolds WordPress site structure
â”œâ”€â”€ docs/                    # PRD, roadmap, sprint docs
â”œâ”€â”€ tests/                   # pytest suites
â”œâ”€â”€ supabase_schema.sql      # full DDL export
â”œâ”€â”€ run_agent.py             # CLI runner for any agent
â”œâ”€â”€ orchestrator.py          # minimal task manager
â”œâ”€â”€ seed_data.py             # populate DB with test data
â”œâ”€â”€ .github/workflows/       # CI pipeline
â””â”€â”€ README.md
```

---

## 4  Quick start â€“ local development (no Docker)

### Prerequisites
* Python 3.10+  
* Node 18+ (for the Next.js dashboard â€“ optional for backend only)

### 1. Clone & create virtual env
```bash
git clone https://github.com/your-org/wordpress-content-generator.git
cd wordpress-content-generator
python3 -m venv venv
source venv/bin/activate
```

### 2. Install dependencies
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 3. Copy environment template & fill credentials
```bash
cp .env.example .env
# edit .env with Supabase/OpenAI keys etc.
```

### 4. Bootstrap the database  
1. Create a new Supabase project  
2. Open SQL editor â†’ paste `supabase_schema.sql` â†’ run  
3. (Optional) seed with sample data  
   ```bash
   python seed_data.py  --reset
   ```

Youâ€™re ready to run agents.

---

## 5  Environment variables

Key vars (see `.env.example`):
```
SUPABASE_URL, SUPABASE_KEY
OPENAI_API_KEY
WP_API_URL, WP_USERNAME, WP_APP_PASSWORD
POCKETFLOW_API_URL, POCKETFLOW_API_KEY
```
Optional dev flag:
```
NEXT_PUBLIC_DEV_AUTH_BYPASS
```
Set to `true` to bypass dashboard authentication during local development.
Put secrets in `.env`; itâ€™s ignored by Git.

---

## 6  Database schema & seed data
* `supabase_schema.sql` â€“ full Postgres DDL (tables, indexes, triggers).  
* `seed_data.py` â€“ inserts:
  * 3 strategic plans
  * 6 content pieces
  * starter keywords, research, hooks
  * initial agent_status rows (queued / done / processing examples)

Run with `--reset` to wipe existing rows.

### 6.1  Required tables

Core agents expect the following tables to exist in Supabase (all included in `supabase_schema.sql`):

| Table            | Purpose (simplified)                          |
| ---------------- | --------------------------------------------- |
| `strategic_plans`| High-level content strategy per domain        |
| `content_pieces` | Individual articles generated by agents       |
| `keywords`       | Focus / supporting keyword clusters           |
| `research`       | Facts, quotes, statistics & sources           |
| `agent_status`   | Queue / log for every agent execution         |

If you create the DB manually, ensure the `research` table (added in this sprint) is included or run `create_research_table.sql` in the Supabase SQL editor.

---

## 7  Running agents manually

### CLI
```bash
python run_agent.py seo-agent agents/seo-agent/test_input.json
```
The runner:
* Dynamically imports `agents/<name>/index.py`
* Prints JSON output to stdout
* Optionally `--output-file result.json`

### Inside code
```python
from agents.seo_agent import run

result = run({"domain": "fitness-blog.com", "niche": "weight training"})
```

---

## 8  Orchestrator
End-to-end pipeline in one command:
```bash
# use existing plan
python orchestrator.py --plan-id <strategic_plan_uuid> --no-ai    # mock data only

# or create a brand-new plan on the fly
python orchestrator.py --create-plan \
  --domain "my-site.com" \
  --audience "DIY-ers" \
  --tone "friendly" \
  --niche "home improvement" \
  --goal "generate leads"
```

Flags worth noting:
* `--no-ai` â€“ run agents with deterministic mock data (no OpenAI credits required).
* `--create-plan` â€“ bootstrap a fresh row in `strategic_plans` then trigger the full workflow.

Internally the orchestrator:
1. Kicks off **Enhanced SEO Agent** â†’ stores keywords + drafts.  
2. Spins up **Research Agent** per new draft.  
3. Runs **Draft Writer Agent** to generate complete article drafts.  
4. Updates `agent_status` rows so the dashboard can show progress.  
5. Retries failures up to `AGENT_MAX_RETRIES`.

---

## 9  Front-end scaffold

Located in `frontend/` (to be added in Sprint 1):  
* Next.js + Tailwind  
* Supabase Auth (email magic-link if multi-user)  
* Live pipeline dashboard (content piece timeline, agent status, error logs)

---

## 10  Continuous integration

GitHub Actions workflow:
* Installs deps, runs **flake8** & **pytest + coverage**
* Publishes coverage to Codecov
* Secrets required for Supabase / OpenAI are injected via repo settings.

---

## 11  Contributing

1. Create feature branch: `feat/seo-agent-improvements`  
2. Follow conventions in **AGENTS.md** â€“ namespaced outputs, shared schemas, idempotent logic.  
3. Add/adjust tests in `tests/`.  
4. Run `black . && isort . && flake8`.  
5. Open pull-request targeting `main`. CI must pass before merge.

---

Happy hacking & GLHF! ðŸ˜Š
